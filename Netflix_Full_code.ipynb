{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36d6cd-ae00-485d-a939-acf081de0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ydata_profiling as pp\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df=pd.read_csv(\"netflix.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.shape # dataset has 5044 rows and 9 columns\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "\n",
    "##Remove the 'Date' column since it's no longer needed after extracting the year, month, and day information.\n",
    "df.drop('Date',axis=1,inplace=True) \n",
    "\n",
    "#Checking for the null values\n",
    "df.isnull().sum()\n",
    "\n",
    "#Count the number of duplicate rows to check data redundancy. A result of 0 indicates no duplicate records.\n",
    "df.duplicated().sum()\n",
    "\n",
    "df.info()#Display information about the dataset, including column data types and memory usage.\n",
    "\n",
    "#Generate descriptive statistics such as mean, standard deviation, min, and max values for each numerical column, providing insights into the data distribution.\n",
    "df.describe()\n",
    "\n",
    "#Compute the correlation matrix to quantify the relationships between different numerical features.\n",
    "corr = df.corr()\n",
    "\n",
    "import missingno as msno \n",
    "msno.bar(df)\n",
    "\n",
    "# Find the number of unique values in each column\n",
    "unique_values = df.nunique()\n",
    "\n",
    "# Display the unique value counts\n",
    "unique_values\n",
    "\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(12, 8))  # Width = 12 inches, Height = 8 inches\n",
    "\n",
    "# Generate the heatmap\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', cbar=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#Create pair plots to visualize pairwise relationships and distributions for all columns in the dataset. Useful for spotting trends and patterns.\n",
    "sns.pairplot(df)\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.distplot(df[i])\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "\n",
    "pp.ProfileReport(df)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Feature Engineering\n",
    "df['Price_Diff'] = df['High'] - df['Low']\n",
    "df['Close_MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "df['Close_Lag_1'] = df['Close'].shift(1)\n",
    "df['Volume_MA_5'] = df['Volume'].rolling(window=5).mean()\n",
    "df['Pct_Change'] = (df['Close'] - df['Open']) / df['Open']\n",
    "\n",
    "df['Price_Diff'],df['Close_MA_5'],df['Close_Lag_1'],df['Volume_MA_5'],df['Pct_Change'] \n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Define features and target\n",
    "X = df[['Open', 'High', 'Low', 'Volume', 'Price_Diff', 'Close_MA_5', 'Close_Lag_1', 'Volume_MA_5', 'Pct_Change']]\n",
    "y = df['Close']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Ridge Regression\n",
    "params = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), params, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best alpha and corresponding Ridge model\n",
    "best_alpha = ridge_grid.best_params_['alpha']\n",
    "print('Best Alpha for Ridge: {best_alpha}')\n",
    "\n",
    "# Train Ridge model with the best alpha\n",
    "ridge_model = Ridge(alpha=best_alpha)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(f'Mean Squared Error (Ridge Regression): {mse_ridge}')\n",
    "\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_ridge})\n",
    "\n",
    "# Set the index to be the range of test samples\n",
    "comparison_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Set up the bar width and positions\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(comparison_df))\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - bar_width/2, comparison_df['Actual'], width=bar_width, label='Actual', color='blue')\n",
    "plt.bar(x + bar_width/2, comparison_df['Predicted'], width=bar_width, label='Predicted', color='orange')\n",
    "plt.xlabel('Test Sample Index')\n",
    "plt.ylabel('Prices')\n",
    "plt.title('Comparison of Actual vs Predicted Prices')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred_ridge\n",
    "\n",
    "# Create a histogram of residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(residuals, bins=20, color='blue', edgecolor='black')\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Zero Residual')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Assuming 'dates' is the index of your DataFrame\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index[-len(y_test):], y_test, label='Actual Prices', color='blue', marker='o')\n",
    "plt.plot(df.index[-len(y_test):], y_pred_ridge, label='Predicted Prices', color='orange', marker='o')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prices')\n",
    "plt.title('Actual vs Predicted Prices Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
